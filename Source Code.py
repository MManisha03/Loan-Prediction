# -*- coding: utf-8 -*-
"""IHLP Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19SySa2xs8cnd9NLOhHEMDVjCK9sy508N
"""

#importing libraries which are necessary
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

#Loading my dataset
data_path = "/loan_data.csv"
data = pd.read_csv(data_path)
#Printing the first 10 dataitems to display whether the dataset is correctly read
print(data.head(10))
#since there is no use of using Loan_Id in testing and training we just droped it
data = data.drop('Loan_ID', axis=1)

#Exploring the dataset
rows,columns = data.shape
#Rows represent number of dataitems
print("Rows:",rows)
#Columns represent Number of Attributes or features
print("Columns:",columns)

from google.colab import drive
drive.mount('/content/drive')

#Dataset Summary to identify trends and understanding the data
summary_stats = data.describe()
print(summary_stats)

#Since my data is not skwed so i think we do not need any transformations of attributes
#Data cleaning and Preprocessing
print(data.isnull().sum())
#replacing the missing values to 0
data.fillna(0, inplace=True)
print(data.isnull().sum())

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
data['Loan_Status'] = label_encoder.fit_transform(data['Loan_Status'])
data.head(10)

#Categorical Features analysis
def encoder(dataframe):
    dataframe['Gender'] = np.where(dataframe['Gender']=='Male', 0, 1)
    dataframe['Married'] = np.where(dataframe['Married']=='No', 0, 1)
    dataframe['Education'] = np.where(dataframe['Education']=='Not Graduate', 0, 1)
    dataframe['Self_Employed'] = np.where(dataframe['Self_Employed']=='No', 0, 1)
    dataframe = pd.get_dummies(dataframe, dtype='int64')
    return dataframe

df = encoder(data)
df.head()

#Spliting the dataset into training set and testing set
from sklearn.model_selection import train_test_split
X = df.drop('Loan_Status', axis=1)
y = data['Loan_Status']
X.fillna(0, inplace=True)
X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Here used 20% data for testing and rest for training

#Implimenting Logistic Regression
from sklearn.linear_model import LogisticRegression
# Initialize the logistic regression model
model = LogisticRegression()
# Train the model on the training data
model.fit(X_train,y_train)
# Predict the loan status for the testing data
y_pred = model.predict(X_test)

#Model Loss Evaluation(Errors)
from sklearn.metrics import mean_squared_error,r2_score
mse = mean_squared_error(y_test , y_pred)
r2 = r2_score(y_test, y_pred)
print("mean squared error:",mse)
print("R-Squared",r2)

#model Performance for Logistic Regression
#caluculating Accuracy
accuracy = accuracy_score(y_test, y_pred)
# Calculating Precision
precision = precision_score(y_test, y_pred)
# Calculating Recall
recall = recall_score(y_test, y_pred)
# Calculating F1-score
f1 = f1_score(y_test, y_pred)
# Calculating ROC AUC score
roc_auc = roc_auc_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("ROC AUC score:", roc_auc)

#stats visualization
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC']
values = [accuracy, precision, recall, f1, roc_auc]
plt.figure(figsize=(10, 6))
plt.bar(metrics, values, color=['blue', 'green', 'red', 'purple', 'orange'])
plt.xlabel('Metrics')
plt.ylabel('Score')
plt.title('Performance Metrics')
plt.ylim(0, 1)
plt.show()

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
#Implimenting SVM(support vector machine)
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)
#Showing scores of SVM
cv_scores = cross_val_score(svm_model, X, y, cv=2,scoring='accuracy')
print("Cross-Validation Scores:", cv_scores)
#since we performed 2 cross validation there are 2 scores so we average them
print("Average Score:", cv_scores.mean())

#model Performance for SVM
accuracy = accuracy_score(y_test, y_pred_svm)
precision = precision_score(y_test, y_pred_svm)
recall = recall_score(y_test, y_pred_svm)
f1 = f1_score(y_test, y_pred_svm)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score",f1)

#stats visualization
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']
values = [accuracy, precision, recall, f1]
plt.figure(figsize=(10, 6))
plt.bar(metrics, values, color=['blue', 'green', 'red', 'purple'])
plt.xlabel('Metrics')
plt.ylabel('Score')
plt.title('Performance Metrics')
plt.ylim(0, 1)
plt.show()